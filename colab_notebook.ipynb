{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXs77m-RHNVc"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pierclgr/SuperResolution/blob/master/MPRNet.ipynb\">\n",
    "      <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# Preliminary steps\n",
    "We first import all the libraries that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 716,
     "status": "ok",
     "timestamp": 1639180067630,
     "user": {
      "displayName": "Pierpasquale Colagrande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBtuRhf9ROCXFdq91UqfNtrBBo_ScM834kCQLLrw=s64",
      "userId": "13718066565975405160"
     },
     "user_tz": -60
    },
    "id": "ep7bVhJIGwSu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import random\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xkg4NWW2HT0y"
   },
   "source": [
    "Then, we set up a function that we can use to obtain the backend device on which the training will be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 523,
     "status": "ok",
     "timestamp": 1639180068610,
     "user": {
      "displayName": "Pierpasquale Colagrande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBtuRhf9ROCXFdq91UqfNtrBBo_ScM834kCQLLrw=s64",
      "userId": "13718066565975405160"
     },
     "user_tz": -60
    },
    "id": "GhFLLyWNHbfl",
    "outputId": "be0364f2-d9d7-49ae-c012-3b243cd7e129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 10 23:47:47 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   33C    P8    27W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      ">>> Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# import torch_xla library if runtime is using a Colab TPU\n",
    "if 'COLAB_TPU_ADDR' in os.environ:\n",
    "    import torch_xla.core.xla_model as xm\n",
    "\n",
    "def get_device() -> str:\n",
    "    \"\"\"\n",
    "    Get the current machine device to use\n",
    "\n",
    "    :returns: the current machine device\n",
    "    \"\"\"\n",
    "\n",
    "    # if the current runtime is using a Colab TPU, define a flag specifying that TPU will be used\n",
    "    if 'COLAB_TPU_ADDR' in os.environ:\n",
    "        use_tpu = True\n",
    "    else:\n",
    "        use_tpu = False\n",
    "\n",
    "    # if TPU is available, use it as device\n",
    "    if use_tpu:\n",
    "        device = xm.xla_device()\n",
    "    else:\n",
    "        # otherwise use CUDA device or CPU accordingly to the one available\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # if the device is a GPU\n",
    "        if torch.cuda.is_available():\n",
    "\n",
    "            # print the details of the given GPU\n",
    "            stream = os.popen('nvidia-smi')\n",
    "            output = stream.read()\n",
    "            print(output)\n",
    "\n",
    "    print(f\">>> Using {device} device\")\n",
    "\n",
    "    return device\n",
    "\n",
    "# get the backend device\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptKZBb6nKSAr"
   },
   "source": [
    "# Data preparation\n",
    "The first step is to prepare the data that will be used for the training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfMwI0Y9KaxE"
   },
   "source": [
    "## Training data\n",
    "As fhe first step, we need to prepare the training data by creating a PyTorch DataLoader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuqQ2_wL31Oc"
   },
   "source": [
    "### Obtain dataset\n",
    "In order to do so, we need to first copy the DIV2K dataset zip file from Google Drive by mounting it, then we need to unzip it. After extracting the images, we delete the zip file in order to free space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "executionInfo": {
     "elapsed": 1798,
     "status": "error",
     "timestamp": 1639180072016,
     "user": {
      "displayName": "Pierpasquale Colagrande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBtuRhf9ROCXFdq91UqfNtrBBo_ScM834kCQLLrw=s64",
      "userId": "13718066565975405160"
     },
     "user_tz": -60
    },
    "id": "SAT7wTluIEc7",
    "outputId": "6e180cb4-4240-43ab-d320-cb0f031a8c6d"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-49-01ff9d34e701>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# mount google drive\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mgoogle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolab\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mdrive\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mdrive\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmount\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'/content/drive'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# copy div2k zip file\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001B[0m in \u001B[0;36mmount\u001B[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001B[0m\n\u001B[1;32m    111\u001B[0m       \u001B[0mtimeout_ms\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtimeout_ms\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    112\u001B[0m       \u001B[0muse_metadata_server\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0muse_metadata_server\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 113\u001B[0;31m       ephemeral=ephemeral)\n\u001B[0m\u001B[1;32m    114\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001B[0m in \u001B[0;36m_mount\u001B[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001B[0m\n\u001B[1;32m    134\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0mephemeral\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    135\u001B[0m     _message.blocking_request(\n\u001B[0;32m--> 136\u001B[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001B[0m\u001B[1;32m    137\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    138\u001B[0m   \u001B[0mmountpoint\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_os\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexpanduser\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmountpoint\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001B[0m in \u001B[0;36mblocking_request\u001B[0;34m(request_type, request, timeout_sec, parent)\u001B[0m\n\u001B[1;32m    173\u001B[0m   request_id = send_request(\n\u001B[1;32m    174\u001B[0m       request_type, request, parent=parent, expect_reply=True)\n\u001B[0;32m--> 175\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mread_reply_from_input\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrequest_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout_sec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001B[0m in \u001B[0;36mread_reply_from_input\u001B[0;34m(message_id, timeout_sec)\u001B[0m\n\u001B[1;32m     99\u001B[0m     \u001B[0mreply\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_read_next_input_message\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    100\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mreply\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_NOT_READY\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreply\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 101\u001B[0;31m       \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.025\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    102\u001B[0m       \u001B[0;32mcontinue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    103\u001B[0m     if (reply.get('type') == 'colab_reply' and\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# copy div2k zip file\n",
    "!echo \"Copying the dataset .zip file from Google Drive (may take a while)...\"\n",
    "!mkdir -p /content/data/ && cp /content/drive/MyDrive/Colab\\ Notebooks/ML4CV/div2k.zip /content/data/\n",
    "!echo \"Done!\"\n",
    "\n",
    "# unzip div2k zip file\n",
    "!echo \"Unzipping the .zip file (may take a while)...\"\n",
    "!unzip -qq /content/data/div2k.zip -d /content/data/\n",
    "!echo \"Done!\"\n",
    "\n",
    "# deleting the copied zip file to free space\n",
    "!echo \"Deleting zip file to free space...\"\n",
    "!rm /content/data/div2k.zip\n",
    "!echo \"Done!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3NMYcz1hsYS"
   },
   "source": [
    "### PyTorch Dataset\n",
    "We first create functions to perform random crops to extract patches and generate random rotations and flips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 795,
     "status": "ok",
     "timestamp": 1639180076205,
     "user": {
      "displayName": "Pierpasquale Colagrande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBtuRhf9ROCXFdq91UqfNtrBBo_ScM834kCQLLrw=s64",
      "userId": "13718066565975405160"
     },
     "user_tz": -60
    },
    "id": "HdNHSUINrpSe"
   },
   "outputs": [],
   "source": [
    "def random_crop(lr: np.ndarray, hr: np.ndarray, scale: int = 2, patch_size: int = 64) -> tuple:\n",
    "    \"\"\"\n",
    "    Extracts a random patch of the given size from an input lr image and the corresponding hr patch scaled using the\n",
    "    given scale.\n",
    "\n",
    "    :param lr: low-resolution image to extract the patch from (ndarray)\n",
    "    :param hr: high-resolution image to extract the patch from (ndarray)\n",
    "    :param scale: scale to use for the extraction of the hr patch (int, default 2)\n",
    "    :param patch_size: size of the low resolution (square) patch (int, default 64)\n",
    "    :return: tuple containing the extacted lr and hr patches\n",
    "    \"\"\"\n",
    "\n",
    "    # extract size of the lr image\n",
    "    height, width = lr.shape[:-1]\n",
    "\n",
    "    # extract random starting coordinates of the patch in the lr image\n",
    "    x = random.randint(0, width - patch_size)\n",
    "    y = random.randint(0, height - patch_size)\n",
    "\n",
    "    # compute the starting coordinates of the patch in the hr image\n",
    "    hr_patch_size = patch_size * scale\n",
    "    hx, hy = x * scale, y * scale\n",
    "\n",
    "    # extract the patch from the two images\n",
    "    lr = lr[y:y + patch_size, x:x + patch_size].copy()\n",
    "    hr = hr[hy:hy + hr_patch_size, hx:hx + hr_patch_size].copy()\n",
    "\n",
    "    return lr, hr\n",
    "\n",
    "\n",
    "def random_horizontal_flip(lr: np.ndarray, hr: np.ndarray, p: float = .5) -> tuple:\n",
    "    \"\"\"\n",
    "    Randomly applies horizontal flip to the given lr and hr patches with the given flipping probability\n",
    "\n",
    "    :param lr: low-resolution patch to flip (ndarray)\n",
    "    :param hr: high-resolution patch to flip (ndarray)\n",
    "    :param p: probability of the flipping (float, default 0.5)\n",
    "    :return: tuple containing the flipped (or not) lr and hr patches\n",
    "    \"\"\"\n",
    "\n",
    "    # flip horizontally the images\n",
    "    if random.random() < p:\n",
    "        lr = np.fliplr(lr)\n",
    "        hr = np.fliplr(hr)\n",
    "\n",
    "    return lr.copy(), hr.copy()\n",
    "\n",
    "\n",
    "def random_90_rotation(lr: np.ndarray, hr: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    Randomly applies a 90° rotation (or not) to the given lr and hr patches\n",
    "\n",
    "    :param lr: low-resolution patch to rotate (ndarray)\n",
    "    :param hr: high-resolution patch to rotate (ndarray)\n",
    "    :return: tuple containing the rotated (or not) lr and hr patches\n",
    "    \"\"\"\n",
    "\n",
    "    # choose a rotation angle (0, 90, -90)\n",
    "    n_rotations = random.choice([0, 1, 3])\n",
    "\n",
    "    # rotate the images\n",
    "    lr = np.rot90(lr, n_rotations)\n",
    "    hr = np.rot90(hr, n_rotations)\n",
    "\n",
    "    return lr.copy(), hr.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32YB_YLlrv3y"
   },
   "source": [
    "We now have to create the PyTorch Dataset in order to make data loadable using a PyTorch DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 490,
     "status": "ok",
     "timestamp": 1639180363596,
     "user": {
      "displayName": "Pierpasquale Colagrande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBtuRhf9ROCXFdq91UqfNtrBBo_ScM834kCQLLrw=s64",
      "userId": "13718066565975405160"
     },
     "user_tz": -60
    },
    "id": "xxAHF0LqZmT7"
   },
   "outputs": [],
   "source": [
    "class DIV2KDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch dataset loading DIV2K HR and LR images\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset_path: str, scales: list = None, split: str = \"train\",\n",
    "                 degradation: str = \"bicubic\", patch_size: int = 64, augment: bool = True) -> None:\n",
    "        \"\"\"\n",
    "        Constructor method of the class\n",
    "\n",
    "        :param dataset_path: path of the folder containing dataset images (str)\n",
    "        :param scales: list containing the resolution scales to consider (list, default None)\n",
    "        :param split: split of the dataset to use (str, default \"train\")\n",
    "        :param degradation: type of degraded images to use (str, default \"bicubic\")\n",
    "        :param patch_size: size of the square (patch_size x patch_size) lr patches to extract (int, default 64)\n",
    "        :param augment: flag to control the augmentation of images (bool, default true)\n",
    "        \"\"\"\n",
    "\n",
    "        super(DIV2KDataset, self).__init__()\n",
    "\n",
    "        # define dataset path\n",
    "        self.dataset_path = dataset_path\n",
    "\n",
    "        # define scales to use if not given\n",
    "        if not scales:\n",
    "            self.scales = [2, 3, 4]\n",
    "        else:\n",
    "            self.scales = scales\n",
    "\n",
    "        # define degradation method to use\n",
    "        self.degradation = degradation.lower()\n",
    "\n",
    "        # define patch size\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        # define split\n",
    "        self.split = split.lower()\n",
    "\n",
    "        # define augmentation\n",
    "        self.augment = augment\n",
    "\n",
    "        # extract the image file names from the dataset\n",
    "        self.filenames = sorted(os.listdir(os.path.join(dataset_path, split, \"hr\")))\n",
    "\n",
    "        # define transform\n",
    "        self.transform = T.Compose([T.ToTensor()])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset\n",
    "\n",
    "        :return: length of the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, item) -> tuple:\n",
    "        \"\"\"\n",
    "        Get a HR image and the corresponding LR images in all the scales\n",
    "\n",
    "        :param item: the chosen item index in the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # select the image to pick\n",
    "        file_name = self.filenames[item]\n",
    "\n",
    "        # extract the HR image from the HR folder\n",
    "        hr_image_path = os.path.join(self.dataset_path, self.split, \"hr\", file_name)\n",
    "        hr_image = io.imread(hr_image_path)\n",
    "\n",
    "        # define the output tuple as empty\n",
    "        output_tuple = ()\n",
    "\n",
    "        # extract the LR images from the LR folder\n",
    "        for scale in self.scales:\n",
    "\n",
    "            # extract the LR image for the current scale from the LR folder\n",
    "            lr_image_path = os.path.join(self.dataset_path, self.split, \"lr\", self.degradation, \"x\" + str(scale), file_name)\n",
    "            lr_image = io.imread(lr_image_path)\n",
    "\n",
    "            # extract the LR and HR patches from the current scaled LR image and the HR image\n",
    "            lr_patch, hr_patch = random_crop(lr_image, hr_image, scale)\n",
    "\n",
    "            # if augmentation is required\n",
    "            if self.augment:\n",
    "                # flip the patches\n",
    "                lr_patch, hr_patch = random_horizontal_flip(lr_patch, hr_patch)\n",
    "\n",
    "                # rotate the patches\n",
    "                lr_patch, hr_patch = random_90_rotation(lr_patch, hr_patch)\n",
    "\n",
    "            # add the current scale_factor-LR-HR triple to the output tuple\n",
    "            output_tuple += (scale, T.ToTensor()(lr_patch), T.ToTensor()(hr_patch))\n",
    "\n",
    "        return output_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvULglMTvJVK"
   },
   "source": [
    "We then create the collate function for the DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1639180375085,
     "user": {
      "displayName": "Pierpasquale Colagrande",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBtuRhf9ROCXFdq91UqfNtrBBo_ScM834kCQLLrw=s64",
      "userId": "13718066565975405160"
     },
     "user_tz": -60
    },
    "id": "6vs9HFPGvM_R"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch: list) -> tuple:\n",
    "    \"\"\"\n",
    "    Collate function for the creation of a dataset\n",
    "\n",
    "    :param batch: list containing the batch samples extracted from the dataset using its __getitem__ method (list)\n",
    "    :return: tuple containing the LR and HR batches in the chosen scale\n",
    "    \"\"\"\n",
    "\n",
    "    # unzip the batch\n",
    "    unzipped = list(zip(*batch))\n",
    "\n",
    "    # choose a random scale from the ones given for the current batch\n",
    "    starting_sub_index = random.randint(0, int(len(unzipped) / 3) - 1) * 3\n",
    "    scale = unzipped[starting_sub_index][0]\n",
    "\n",
    "    # stack the hr and lr batches into a unique PyTorch tensor\n",
    "    lr = torch.stack(unzipped[starting_sub_index + 1])\n",
    "    hr = torch.stack(unzipped[starting_sub_index + 2])\n",
    "\n",
    "    # return the batch\n",
    "    return scale, lr, hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCmSycozxdT6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now test the dataset and DataLoader speed in loading images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset = DIV2KDataset(\"/content/data/div2k\")\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn, num_workers=2, pin_memory=True)\n",
    "\n",
    "train_dataset.__getitem__(0)\n",
    "start = time.time()\n",
    "for _ in tqdm(train_dataloader):\n",
    "    pass\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPaokgQ0tsDaXkEL1WZaF81",
   "collapsed_sections": [],
   "name": "New_MPRNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3047b0b96eb04694bfa6df4b627d545d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "360ae3929ddd40578a3e4850ecd9ef02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a026cd4b3e4c4d52b2cadc915f8149ec",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ff00f6ba41a45018c2dbedd48368b37",
      "value": 7
     }
    },
    "730f96da82c4476685115479bb0ddfdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d47fa67129654ffca0ef8f7ad01ab199",
      "placeholder": "​",
      "style": "IPY_MODEL_cad79944fbc4476daeb26b37d3d9b497",
      "value": " 7/7 [00:18&lt;00:00,  1.66s/it]"
     }
    },
    "848636d74ccb43c4890ae15b4a889f2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e164a425ebcc44d6893b48c095d870f5",
       "IPY_MODEL_360ae3929ddd40578a3e4850ecd9ef02",
       "IPY_MODEL_730f96da82c4476685115479bb0ddfdf"
      ],
      "layout": "IPY_MODEL_ed3f483dd2eb4521a8d9f0c527447a76"
     }
    },
    "9ff00f6ba41a45018c2dbedd48368b37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a026cd4b3e4c4d52b2cadc915f8149ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abc6b4dadf2f493cbb6254caabe591dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cad79944fbc4476daeb26b37d3d9b497": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d47fa67129654ffca0ef8f7ad01ab199": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e164a425ebcc44d6893b48c095d870f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_abc6b4dadf2f493cbb6254caabe591dd",
      "placeholder": "​",
      "style": "IPY_MODEL_3047b0b96eb04694bfa6df4b627d545d",
      "value": "100%"
     }
    },
    "ed3f483dd2eb4521a8d9f0c527447a76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}